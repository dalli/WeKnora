# WeKnora 하드웨어 구성 추천 가이드

## 개요
- **등록 사용자**: 200명
- **동시 사용자**: 10명
- **아키텍처**: RAG 기반 문서 이해 및 검색 프레임워크

## 시나리오 1: 외부 LLM 서비스 사용

### 전체 구성 개요
외부 LLM 서비스를 사용하는 경우, GPU 서버 없이 CPU 기반 서버만으로 운영 가능합니다.

### 권장 하드웨어 구성

#### 옵션 A: 단일 서버 구성 (소규모/비용 효율적)

**서버 사양:**
- **CPU**: Intel Xeon E5-2686 v4 (14코어) 또는 AMD EPYC 7B12 (16코어) 이상
- **메모리**: 32GB RAM (권장: 64GB)
- **스토리지**: 
  - SSD 500GB (OS + 애플리케이션)
  - SSD 1TB (데이터베이스 + 벡터 인덱스)
- **네트워크**: 1Gbps 이상

**예상 비용**: 월 $100-200 (클라우드 기준)

**구성 이유:**
- 동시 사용자 10명은 단일 서버로 충분히 처리 가능
- PostgreSQL (ParadeDB) 벡터 검색은 CPU 집약적이지만 10명 동시 사용에는 부담 없음
- Redis, DocReader 등 모든 서비스를 단일 서버에서 컨테이너로 실행

**리소스 할당:**
```
Frontend (Nginx):     0.5 CPU, 512MB RAM
App (Go):             2 CPU, 4GB RAM
DocReader (Python):   2 CPU, 4GB RAM
PostgreSQL:           4 CPU, 8GB RAM
Redis:                1 CPU, 2GB RAM
기타 (MinIO 등):      1 CPU, 2GB RAM
여유:                 4 CPU, 11GB RAM
```

#### 옵션 B: 분리 구성 (안정성/확장성 중시)

**서버 1: 애플리케이션 서버**
- **CPU**: 8코어 이상
- **메모리**: 16GB RAM
- **스토리지**: SSD 200GB
- **역할**: Frontend, App, DocReader, Redis

**서버 2: 데이터베이스 서버**
- **CPU**: 8코어 이상 (벡터 검색 최적화)
- **메모리**: 32GB RAM (벡터 인덱스 캐싱)
- **스토리지**: SSD 1TB (고성능)
- **역할**: PostgreSQL (ParadeDB)

**예상 비용**: 월 $200-300 (클라우드 기준)

**구성 이유:**
- 데이터베이스와 애플리케이션 분리로 안정성 향상
- 데이터베이스 서버에 더 많은 리소스 할당 가능
- 향후 확장 시 유연성 확보

### 스토리지 계획

**데이터 예상량 (200명 사용자 기준):**
- 문서 저장: 평균 사용자당 100MB = 20GB
- 벡터 인덱스: 문서의 약 20-30% = 4-6GB
- 데이터베이스 메타데이터: 2-3GB
- 로그 및 임시 파일: 5-10GB
- **총 예상**: 약 35-45GB (여유 포함 100GB 이상 권장)

### 네트워크 요구사항

- **대역폭**: 최소 100Mbps (권장: 1Gbps)
- **지연시간**: 외부 LLM API 호출 시 < 100ms (같은 리전 권장)
- **방화벽**: 
  - 인바운드: 80 (HTTP), 443 (HTTPS), 8080 (API, 내부)
  - 아웃바운드: 외부 LLM API 접근 허용

---

## 시나리오 2: vLLM을 이용한 GPU 서버 구성

### 전체 구성 개요
vLLM을 사용하여 자체 LLM 서빙을 하는 경우, GPU 서버가 필수입니다.

### 권장 하드웨어 구성

#### 옵션 A: 단일 GPU 서버 + CPU 서버 구성

**서버 1: GPU 서버 (LLM 서빙)**
- **GPU**: NVIDIA A10 (24GB) 또는 RTX 4090 (24GB) 1개
  - 7B 모델: A10 1개 또는 RTX 4090 1개
  - 13B 모델: A10 1개 (양자화 필요 시 RTX 4090도 가능)
  - 70B 모델: A100 (40GB) 2개 이상 권장
- **CPU**: Intel Xeon 또는 AMD EPYC 8코어 이상
- **메모리**: 64GB RAM (GPU 메모리와 별도)
- **스토리지**: SSD 500GB (모델 저장용)
- **네트워크**: 10Gbps 권장

**서버 2: 애플리케이션 서버**
- **CPU**: 8코어 이상
- **메모리**: 32GB RAM
- **스토리지**: SSD 500GB
- **역할**: Frontend, App, DocReader, Redis

**서버 3: 데이터베이스 서버**
- **CPU**: 8코어 이상
- **메모리**: 32GB RAM
- **스토리지**: SSD 1TB
- **역할**: PostgreSQL (ParadeDB)

**예상 비용**: 월 $800-1,500 (클라우드 기준, GPU 포함)

#### 옵션 B: 통합 구성 (비용 절감)

**서버 1: GPU + 애플리케이션 통합 서버**
- **GPU**: NVIDIA A10 (24GB) 또는 RTX 4090 (24GB) 1개
- **CPU**: 16코어 이상
- **메모리**: 64GB RAM
- **스토리지**: SSD 1TB
- **역할**: vLLM, Frontend, App, DocReader, Redis

**서버 2: 데이터베이스 서버**
- **CPU**: 8코어 이상
- **메모리**: 32GB RAM
- **스토리지**: SSD 1TB
- **역할**: PostgreSQL (ParadeDB)

**예상 비용**: 월 $600-1,000 (클라우드 기준)

### vLLM 모델별 리소스 요구사항

#### 7B 모델 (예: Qwen2-7B, Llama-3-8B)
- **GPU 메모리**: 14-16GB (FP16), 8-10GB (INT8)
- **권장 GPU**: RTX 4090 (24GB) 또는 A10 (24GB)
- **동시 요청**: 10명 기준으로 충분 (vLLM의 continuous batching 활용)

#### 13B 모델 (예: Qwen2-13B, Llama-3-13B)
- **GPU 메모리**: 26-28GB (FP16), 14-16GB (INT8)
- **권장 GPU**: A10 (24GB) - INT8 양자화 필수, 또는 A100 (40GB)
- **동시 요청**: 10명 기준으로 충분

#### 70B 모델 (예: Qwen2-72B)
- **GPU 메모리**: 140GB+ (FP16), 70GB+ (INT8)
- **권장 GPU**: A100 (40GB) 2개 이상 (Tensor Parallelism 필요)
- **동시 요청**: 10명 기준으로 충분하지만 리소스 과다

**권장**: 7B-13B 모델이 10명 동시 사용자 규모에 적합

### vLLM 설정 권장사항

```yaml
# vLLM 서버 설정 예시
gpu_memory_utilization: 0.9  # GPU 메모리 90% 사용
max_model_len: 4096          # 컨텍스트 길이
tensor_parallel_size: 1      # 단일 GPU
max_num_seqs: 32            # 동시 처리 시퀀스 수 (10명 기준 충분)
```

### 네트워크 구성

**GPU 서버와 애플리케이션 서버 간:**
- **대역폭**: 최소 1Gbps (권장: 10Gbps)
- **지연시간**: < 10ms (같은 데이터센터 권장)
- **포트**: vLLM API 포트 (기본 8000)

---

## 공통 고려사항

### 모니터링 및 로깅

**권장 도구:**
- **Jaeger**: 분산 추적 (선택적, 개발/디버깅용)
- **Prometheus + Grafana**: 메트릭 수집 및 시각화
- **ELK Stack**: 로그 집계 (선택적)

**리소스 요구사항:**
- CPU: 1-2 코어
- 메모리: 2-4GB
- 스토리지: 50GB (로그 보관)

### 백업 및 재해복구

**백업 전략:**
- **데이터베이스**: 일일 자동 백업 (PostgreSQL dump)
- **벡터 인덱스**: 데이터베이스 백업에 포함
- **문서 파일**: MinIO/S3 버전 관리 또는 일일 스냅샷
- **보관 기간**: 최소 7일, 권장 30일

**스토리지 요구사항:**
- 백업 저장소: 데이터의 2-3배 (약 100-150GB)

### 보안

**필수 구성:**
- SSL/TLS 인증서 (Let's Encrypt 등)
- 방화벽 규칙 (필요한 포트만 개방)
- 정기적인 보안 업데이트
- 데이터베이스 암호화 (at rest)

### 확장성 고려사항

**현재 규모 (10명 동시 사용자)에서 다음 단계로 확장 시:**

1. **동시 사용자 50명:**
   - CPU 서버: 16코어, 64GB RAM
   - 데이터베이스: 16코어, 64GB RAM
   - GPU 서버: 동일 (vLLM은 continuous batching으로 확장 가능)

2. **동시 사용자 100명:**
   - 애플리케이션 서버: 수평 확장 (로드 밸런서 필요)
   - 데이터베이스: 읽기 전용 복제본 추가
   - GPU 서버: 더 큰 모델 또는 추가 GPU 고려

---

## 비용 비교 요약

| 구성 | 초기 비용 | 월간 운영비 | 적합한 시나리오 |
|------|----------|-----------|---------------|
| 외부 LLM (단일 서버) | $500-1,000 | $100-200 | 소규모, 빠른 시작 |
| 외부 LLM (분리 구성) | $1,000-2,000 | $200-300 | 안정성 중시 |
| vLLM (통합 구성) | $3,000-5,000 | $600-1,000 | 데이터 프라이버시, 비용 절감 |
| vLLM (분리 구성) | $5,000-8,000 | $800-1,500 | 대규모, 최고 성능 |

**참고**: 
- 외부 LLM API 비용은 별도 (토큰 사용량에 따라 변동)
- vLLM은 초기 투자 높지만 장기적으로 비용 효율적일 수 있음
- GPU 서버는 온프레미스 구매 시 초기 비용이 높지만 장기 운영 시 클라우드보다 저렴할 수 있음

---

## 최종 권장사항

### 외부 LLM 사용 시
**권장**: 옵션 A (단일 서버 구성)
- 10명 동시 사용자 규모에는 단일 서버로 충분
- 비용 효율적이며 관리 간편
- 향후 확장 시 분리 구성으로 전환 가능

### vLLM 사용 시
**권장**: 옵션 B (통합 구성)
- GPU 서버에 애플리케이션 통합으로 네트워크 지연 최소화
- 데이터베이스는 별도 서버로 분리하여 안정성 확보
- 7B-13B 모델 사용 권장 (10명 동시 사용자에 적합)

---

## 체크리스트

### 배포 전 확인사항
- [ ] 서버 사양이 최소 요구사항 충족
- [ ] 스토리지 용량 계획 수립
- [ ] 네트워크 대역폭 확인
- [ ] 백업 전략 수립
- [ ] 모니터링 도구 설정
- [ ] 보안 설정 완료
- [ ] SSL 인증서 준비
- [ ] 방화벽 규칙 구성

### 운영 중 모니터링 지표
- CPU 사용률 (목표: < 70%)
- 메모리 사용률 (목표: < 80%)
- 디스크 I/O (SSD 권장)
- 네트워크 대역폭
- 데이터베이스 연결 수
- API 응답 시간 (목표: < 2초)
- GPU 사용률 (vLLM 사용 시, 목표: 70-90%)

